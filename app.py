# app.py - Vers√£o Pura e Focada no Agente Conversacional

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import io
import contextlib

from langchain_groq import ChatGroq

st.set_page_config(page_title="ü§ñ Agente de An√°lise de Dados", layout="wide")
st.title("ü§ñ Agente de An√°lise de Dados Conversacional")

# --- Estado da Sess√£o ---
if "history" not in st.session_state:
    st.session_state.history = []
if "df" not in st.session_state:
    st.session_state.df = None
if "llm" not in st.session_state:
    st.session_state.llm = None

# --- Barra Lateral ---
with st.sidebar:
    st.header("Configura√ß√£o")
    uploaded_file = st.file_uploader("1. Carregue seu arquivo CSV", type="csv")

    if st.button("Resetar Sess√£o"):
        st.session_state.clear()
        st.rerun()

    # Adiciona um espa√ßo para manter a barra lateral limpa
    st.sidebar.markdown("---")
    st.sidebar.write("Desenvolvido com a sua colabora√ß√£o.")
    st.sidebar.write("Foco: 100% na intera√ß√£o com o agente.")


# --- L√≥gica de Inicializa√ß√£o ---
if uploaded_file is not None and st.session_state.df is None:
    with st.spinner("Carregando arquivo e inicializando o agente..."):
        try:
            st.session_state.df = pd.read_csv(uploaded_file)
            groq_api_key = st.secrets["GROQ_API_KEY"]
            st.session_state.llm = ChatGroq(temperature=0, model_name="gemma2-9b-it", groq_api_key=groq_api_key)
            # Mensagem de boas-vindas no chat
            st.session_state.history.append({
                "role": "assistant",
                "content": f"Arquivo `{uploaded_file.name}` carregado com sucesso! Sou seu assistente de an√°lise de dados. O que voc√™ gostaria de saber?"
            })
        except Exception as e:
            st.error(f"Erro na inicializa√ß√£o: {e}")

# --- Interface Principal ---

if st.session_state.df is None:
    st.info("üëÜ Para come√ßar, carregue um arquivo CSV na barra lateral.")
else:
    # A interface de chat √© agora o elemento central
    st.header("Converse com seus Dados")

    # Exibe o hist√≥rico de mensagens
    for message in st.session_state.history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Input do usu√°rio
    if user_prompt := st.chat_input("Ex: 'Qual a m√©dia da coluna X?' ou 'Gere um histograma para Y'"):
        st.session_state.history.append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(user_prompt)

        # Gera e exibe a resposta do assistente
        with st.chat_message("assistant"):
            with st.spinner("Analisando sua pergunta e gerando o c√≥digo..."):
                df = st.session_state.df # Disponibiliza o df para o exec()
                
                # Formata o hist√≥rico para o prompt
                formatted_history = ""
                for message in st.session_state.history:
                    role = "Usu√°rio" if message["role"] == "user" else "Assistente (c√≥digo gerado)"
                    formatted_history += f"{role}: {message['content']}\n"

                # Prompt com mem√≥ria
                code_generation_prompt = f"""
                Voc√™ √© um especialista em Python, pandas e matplotlib. Continue a conversa abaixo gerando o pr√≥ximo bloco de c√≥digo Python necess√°rio para responder √† √∫ltima pergunta do usu√°rio.
                Considere todo o hist√≥rico da conversa para entender o contexto.

                ### Hist√≥rico da Conversa ###
                {formatted_history}
                ### Fim do Hist√≥rico ###

                Baseado na √∫ltima pergunta do usu√°rio e no contexto acima, gere o pr√≥ximo c√≥digo Python.
                - Para perguntas que retornam um valor (c√°lculos, dtypes, describe), **SEMPRE** use a fun√ß√£o `print()`.
                - Para perguntas que pedem um gr√°fico, use `plt.show()`.
                - Forne√ßa apenas o bloco de c√≥digo Python, sem explica√ß√µes.
                """
                
                code_response = st.session_state.llm.invoke(code_generation_prompt)
                generated_code = code_response.content.strip().replace("```python", "").replace("```", "").strip()
                
                if "plt.show()" not in generated_code and "print(" not in generated_code:
                    generated_code = f"print({generated_code})"

                st.write("C√≥digo gerado:")
                st.code(generated_code)

            with st.spinner("Executando c√≥digo e preparando a resposta..."):
                output_buffer = io.StringIO()
                try:
                    if "plt.show()" in generated_code:
                        fig, ax = plt.subplots()
                        exec(generated_code.replace("plt.show()", ""), {"df": df, "plt": plt, "ax": ax})
                        st.pyplot(fig)
                        plt.close(fig)
                        st.session_state.history.append({"role": "assistant", "content": f"*(C√≥digo do gr√°fico executado: `{generated_code}`)*"})
                    else:
                        with contextlib.redirect_stdout(output_buffer):
                            exec(generated_code, {"df": df})
                        text_output = output_buffer.getvalue().strip()
                        st.session_state.history.append({"role": "assistant", "content": generated_code})
                        final_response_text = f"**Resultado:**\n```\n{text_output}\n```"
                        st.markdown(final_response_text)
                except Exception as e:
                    error_message = f"Ocorreu um erro ao executar o c√≥digo: {e}"
                    st.error(error_message)
                    st.session_state.history.append({"role": "assistant", "content": f"Erro: {error_message}"})

